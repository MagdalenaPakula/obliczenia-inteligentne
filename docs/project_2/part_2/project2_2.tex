\documentclass[10pt]{article}

\input{../../prelude.tex}
\title{Projekt 2 --- Zadanie 2}

\captionsetup{font=small}

\newcommand{\plotAccuraciesFromLoggedMetrics}[1]{
    \begin{tikzpicture}
        \begin{axis}[
            width=\linewidth,
            height=.5\linewidth,
            legend pos = south east,
            grid = major,
            legend style={font=\tiny},
            style = {font=\small},
            ymin=0, ymax=1
        ]
            \addplot+[mark=none] table[x = epoch, y = train_acc] {#1};
            \addlegendentry{Train acc};

            \addplot+[mark=none, orange] table[x = epoch, y = val_acc] {#1};
            \addlegendentry{Test acc};
        \end{axis}
    \end{tikzpicture}
}


\begin{document}

\maketitle
\normalsize

\section{Eksperyment 1: Architektury sieci splotowej dla MNIST (Jakub Pawlak)}\label{sec:ex1-pawlak_mnist}

\subsection*{Pierwsza architektura}


\pgfplotstableread[col sep=comma]{data/kuba/mnist/large.csv}\kubaMnistLarge{}

\begin{figure}[H]\centering
    \begin{subfigure}[t]{.6\textwidth}
        \plotAccuraciesFromLoggedMetrics{\kubaMnistLarge}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{.34\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/kuba/mnist/large_cm.png}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \caption{Wyniki dla 1 architektury}
\end{figure}


\subsection*{Druga architektura, prowadząca do ekstrakcji 2 cech}

\tiny
\begin{verbatim}
(feature_extractor): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): Sigmoid()
    (2): Dropout2d(p=0.1, inplace=False)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): Sigmoid()
    (6): Dropout2d(p=0.1, inplace=False)
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Conv2d(16, 2, kernel_size=(5, 5), stride=(1, 1))
    (9): Sigmoid()
    (10): Flatten(start_dim=1, end_dim=-1)
)
(classifier): Sequential(
    (0): Linear(in_features=2, out_features=5, bias=True)
    (1): ReLU()
    (2): Linear(in_features=5, out_features=10, bias=True)
)
\end{verbatim}
\normalsize

\pgfplotstableread[col sep=comma]{data/kuba/mnist/smol.csv}\kubaMnistSmol{}

\begin{figure}[H]\centering
    \begin{subfigure}[t]{.6\textwidth}
        \plotAccuraciesFromLoggedMetrics{\kubaMnistSmol}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{.34\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/kuba/mnist/smol_cm.png}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \caption{Wyniki dla 2 architektury}
\end{figure}

\pagebreak
\section{Eksperyment 1: Architektury sieci splotowej dla MNIST (Magdalena Pakuła)}\label{sec:ex1-pakula_mnist}

\subsection*{Pierwsza architektura}
Zawiera trzy warstwy splotowe każda warstwa wydobywa coraz bardziej abstrakcyjne cechy. Warstwy początkowe rejestrują krawędzie i tekstury, podczas gdy warstwy głębsze rejestrują kształty i bardziej złożone wzory. Ma to kluczowe znaczenie w przypadku rozpoznawania cyfr, gdzie należy rozróżnić subtelne różnice.
Po każdej wartwie splotowej następuje redukcja wymiarowości, dzięki użyciu MaxPool2d, co pozwala sieci skupić się na najbardziej istotnych cechach cyfr, poprawiając generalizację.
Stopniowy wzrost filtrów (zaczynając od 8, a kończąc na 32) zapewnia równowagę między wydajnością obliczeniową a bogactwem funkcji.
Ostatecznie model zostaje spłaszczony do 288 obiektów, wystarczającą pojemność do reprezentowania złożonych wzorów, nie będąc jednocześnie zbyt dużym, co mogłoby prowadzić do nadmiernego dopasowania.
Rezultaty tej metody zostały przedstawione poniżej na wykresie accuracy, macierzy pomyłek i wyników accurracy i loss najlepszego modelu na rys. ~\ref{fig:exp1_magda_mnist}.

\pgfplotstableread[col sep=comma]{data/magda/mnist/large.csv}\MagdaMnistLarge{}

\begin{figure}[H]\centering
    \begin{subfigure}[b]{.4\textwidth}
        \plotAccuraciesFromLoggedMetrics{\MagdaMnistLarge}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \begin{subfigure}[b]{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/MNIST_large_matrix}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \begin{subfigure}[b]{.24\textwidth}
        \centering
        \scriptsize
        \begin{tabular}{|c|c|}
            \hline
            Test metric & Result \\
            \hline
            Test acc & 0.984 \\
            Test loss & 0.045 \\
            \hline
        \end{tabular}
        \caption{Wyniki accuracy i loss najlepszego modelu (epoch 5)}
    \end{subfigure}
    \caption{Wyniki dla 1 architektury}
    \label{fig:exp1_magda_mnist}
\end{figure}


\subsection*{Druga architektura, prowadząca do ekstrakcji 2 cech}
Składa się z czterech warstw splotowych. Liczba filtrów w tych warstwach jest hierarchicznie zwiększana od 32 do 128. Po każdej warstwie splotowej następuje normalizacja wsadowa (BatchNorm2d), funkcja aktywacji ReLU i redukcja wymiarowości poprzez użycie operacji MaxPool2d, z wyjątkiem ostatniej warstwy, gdzie ta operacja nie jest już potrzebna.
Taka konfiguracja została zaprojektowana w celu stopniowego wyodrębniania coraz bardziej skomplikowanych cech z obrazów MNIST. Pierwsze warstwy koncentrują się na wykrywaniu podstawowych cech, takich jak krawędzie i rogi, dzięki mniejszej liczbie filtrów. Następnie, w kolejnych warstwach, liczba filtrów jest stopniowo zwiększana.
Operacje normalizacji wsadowej pomagają w stabilizacji uczenia poprzez zapewnienie jednolitego zakresu wartości na wyjściu z każdej warstwy, co może przyspieszyć proces uczenia oraz poprawić ogólną wydajność sieci. Funkcja aktywacji ReLU została wybrana z powodu jej skuteczności w eliminowaniu zjawiska zanikającego gradientu i aktywowania jedynie istotnych cech.

Rezultaty tej metody zostały przedstawione poniżej na rys. ~\ref{fig:exp1_magda_mnist2}.

\pgfplotstableread[col sep=comma]{data/magda/mnist/small.csv}\MagdaMnistSmall{}

\begin{figure}[H]\centering
    \begin{subfigure}[b]{.4\textwidth}
        \plotAccuraciesFromLoggedMetrics{\MagdaMnistSmall}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/MNIST_small_matrix}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \scriptsize
        \begin{tabular}{|c|c|}
            \hline
            Test metric & Result \\
            \hline
            Test acc & 0.869 \\
            Test loss & 0.388 \\
            \hline
        \end{tabular}
        \caption{Wyniki accuracy i loss najlepszego modelu (epoch 5)}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/MNIST_small_decision}
        \caption{Wizualizacja granic decyzyjnych}
    \end{subfigure}
    \caption{Wyniki dla 2 architektury}
    \label{fig:exp1_magda_mnist2}
\end{figure}

\pagebreak
\section{Eksperyment 1: Architektury sieci splotowej dla CIFAR10 (Jakub Pawlak)}\label{sec:ex1-pawlak_cifar}

\paragraph{Pierwsza architektura}

\pgfplotstableread[col sep=comma]{data/kuba/cifar/large.csv}\kubaCifarLarge{}

\begin{figure}[H]\centering
    \begin{subfigure}[t]{.6\textwidth}
        \plotAccuraciesFromLoggedMetrics{\kubaCifarLarge}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{.34\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/kuba/cifar/large_cm.png}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \caption{Wyniki dla 1 architektury}
\end{figure}


\paragraph{Druga architektura prowadząca do ekstrakcji 2 cech}

\pgfplotstableread[col sep=comma]{data/kuba/cifar/smol.csv}\kubaCifarSmol{}

\begin{figure}[H]\centering
    \begin{subfigure}[t]{.6\textwidth}
        \plotAccuraciesFromLoggedMetrics{\kubaCifarSmol}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \hspace{2em}
    \begin{subfigure}[t]{.34\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/kuba/cifar/smol_cm.png}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \caption{Wyniki dla 2 architektury}
\end{figure}

\pagebreak
\section{Eksperyment 1: Architektury sieci splotowej dla CIFAR10 (Magdalena Pakuła)}\label{sec:ex1-pakula_cifar}

\subsection*{Pierwsza architektura}
Składa się z trzech warstw splotowych, gdzie każda z nich wykorzystuje coraz większą liczbę filtrów o rozmiarze 3x3
Pierwsza warstwa splotowa zawiera 32 filtry, stosuje funkcję aktywacji ReLU oraz warstwę Dropout z współczynnikiem 0.2, która losowo wyłącza część neuronów, zapobiegając nadmiernemu dopasowaniu. Następnie warstwa MaxPooling zmniejsza rozmiar przestrzenny danych o połowę. Druga warstwa splotowa składa się z 64 filtrów, ponownie stosuje ReLU oraz Dropout z współczynnikiem 0.3, a także warstwę MaxPooling, która zmniejsza rozmiar przestrzenny danych do 8x8. Trzecia warstwa splotowa zawiera 128 filtrów, stosuje ReLU, Dropout z współczynnikiem 0.4 oraz MaxPooling, zmniejszając rozmiar przestrzenny danych do 4x4. Dane są następnie spłaszczone do jednowymiarowego tensora za pomocą warstwy Flatten, umożliwiając przekazanie ich do warstw w pełni połączonych w celu klasyfikacji. Klasyfikator składa się z dwóch warstw w pełni połączonych, gdzie pierwsza redukuje rozmiar cech do 128, stosując funkcję ReLU oraz Dropout z współczynnikiem 0.5, a druga warstwa klasyfikuje dane do liczby klas
Ta architektura została zoptymalizowana w celu efektywnego wyodrębniania cech z obrazów o niskiej rozdzielczości, takich jak te występujące w zbiorze CIFAR. Większa liczba warstw splotowych oraz zwiększenie liczby filtrów w każdej warstwie pozwalają na lepsze modelowanie danych
Rezultaty tej metody zostały przedstawione na rys. ~\ref{fig:exp1_magda_cifar}.

\pgfplotstableread[col sep=comma]{data/magda/cifar/large.csv}\MagdaCifarLarge{}

\begin{figure}[H]\centering
    \begin{subfigure}[b]{.4\textwidth}
        \plotAccuraciesFromLoggedMetrics{\MagdaCifarLarge}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \begin{subfigure}[b]{.24\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/CIFAR_large_matrix}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \begin{subfigure}[b]{.24\textwidth}
        \centering
        \scriptsize
        \begin{tabular}{|c|c|}
            \hline
            Test metric & Result \\
            \hline
            Test accuracy & 0.735 \\
            Test loss & 0.841 \\
            \hline
        \end{tabular}
        \caption{Wyniki accuracy i loss najlepszego modelu (epoch 7)}
    \end{subfigure}
    \caption{Wyniki dla 1 architektury}
    \label{fig:exp1_magda_cifar}
\end{figure}


\subsection*{Druga architektura prowadząca do ekstrakcji 2 cech}
Składa się z 4 warstw splotowych z 32, 64 i 128 filtrami, które pozwalają na stopniowe wyodrębnianie coraz bardziej złożonych
cech z danych wejściowych. Następie użycie BatchNorm2d stabilizuje proces treningu i pozwala na szybsze uczenie się modelu,
a funkcja aktywacji ReLU wprowadza nieliniowość. Następnie jest wartswa MaxPooling redukująca rozmiar danych.
Ostatnia warstwa splotowa prowadzi do 2 filtrów. A na końcu dodana jest Ffnkcja aktywacji ReLU.
Klasyfikator składa się z trzech warstw w pełni połączonych, które stopniowo redukują rozmiar cech i umożliwiają klasyfikację danych do odpowiedniej liczby klas. Dropout (0.3) w pierwszej warstwie w pełni połączonej zapobiega nadmiernemu dopasowaniu modelu poprzez losowe wyłączanie neuronów podczas treningu.

Rezultaty przedstawione są na rys. ~\ref{fig:exp1_magda_cifar2}.

\pgfplotstableread[col sep=comma]{data/magda/cifar/small.csv}\MagdaCifarLSmall{}

\begin{figure}[H]\centering
    \begin{subfigure}[b]{.4\textwidth}
        \plotAccuraciesFromLoggedMetrics{\MagdaCifarSmall}
        \caption{Wykres zmian accuracy}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/Cifar_small_matrix}
        \caption{Macierz pomyłek}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \scriptsize
        \begin{tabular}{|c|c|}
            \hline
            Test metric & Result \\
            \hline
            Test acc & 0.869 \\
            Test loss & 0.388 \\
            \hline
        \end{tabular}
        \caption{Wyniki accuracy i loss najlepszego modelu (epoch 5)}
    \end{subfigure}
    \begin{subfigure}[b]{.19\textwidth}
        \centering
        \includegraphics[width=\linewidth]{img/magda/Cifar_small_decision}
        \caption{Wizualizacja granic decyzyjnych}
    \end{subfigure}
    \caption{Wyniki dla 2 architektury}
    \label{fig:exp1_magda_cifar2}
\end{figure}

\pagebreak
\section{Eksperyment 2: Wyniki dla MNIST}\label{sec:ex2_mnist}

\paragraph{Najlepsza architektura}
\paragraph{Najelpsza architektura prowadząca do ekstrakcji 2 cech}

\pagebreak
\section{Eksperyment 2: Wyniki dla CIFAR10}\label{sec:ex2_cifar}

\paragraph{Najlepsza architektura}
\paragraph{Najelpsza architektura prowadząca do ekstrakcji 2 cech}

\pagebreak
\section{Analiza i wnioski}\label{sec:wyniki}
\subsection*{Porównanie architektur sieci splotowych}
Generalne wnioski Magdy dla MNIST: wyszlo zajebiscie, rezultaty same pokazuja - mozna sie bić :)
Generalne wnioski Magdy dla CIFAR: nie wyszlo zajebiscie, wyniki sa słabe. Dla 1 archi nie udalo mi sie stworzyc modelu ktory by nie robil underfittug - wszystkie mniej czy wiecej to robily, a dla zachowania podobnych experymentow co Kuba to nie zmienialam learning rate. Zmienialam relu, conv layers, filters ale obecny model to moj najlepszy.
Jesli chodzi o Archi 2 to tez moj najlepszy model ktory stworzylam, mamy znowu lekki underfitting
wiadomka ze dla 2 cech beda to znacznie gorsze wyniki w szczegolnosci dla tak skomplikownych i nieczytelnych obrazkow jak CIFAR.

Model Kuby dla Cifara jest better bo... - tutaj wyjasnienie czemu jest taki boski.
\subsection*{Wpływ augmentacji danych}

\end{document}